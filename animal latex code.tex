
\documentclass{article}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}

\title{Animal Image Classification latex code}
\author{Using CNN}
\date{}

\begin{document}
\maketitle

\section{Introduction}
This document is an auto-generated LaTeX conversion of a Jupyter Notebook.

\section{Markdown Content}
# **Image Preprocessing**

Before training a deep learning model, images need to be preprocessed. The key steps include:

*  **Resizing & Cropping** - Ensures all images are of the same size.

*  **Normalization** - Scales pixel values to [0,1] or [-1,1] to speed up training.

*  **Handling Color Channels** - Convert images to RGB (3 channels).

*  **Data Augmentation** - Enhances dataset diversity using transformations (flips, rotations, zooms).

# **Model Development**

Deep learning models learn to classify images by extracting patterns from pixel values. There are two main approaches:

1. ***CNN from Scratch:***

*  Uses convolutional layers to extract features.

*  Needs more training data and computational power.

2.  ***Transfer Learning (Recommended):***

*  Uses a pre-trained model (e.g., ResNet, VGG16) trained on large datasets like ImageNet.
*  Faster training and better accuracy.
*  We only fine-tune the last layers.

# **Handling Class Imbalance**

In real-world datasets, some classes may have fewer images than others. This imbalance can cause the model to:

*  Overfit to majority classes

*  Misclassify minority classes

To fix class imbalance, we use:

*  **Data Augmentation (Recommended)** - Artificially increase dataset size by applying transformations.

*  **Class Weighting** - Assign higher loss weights to minority classes.

*  **Resampling** - Oversample minority classes or undersample majority classes.

# **Explainability**

 Using Grad-CAM Theory Neural networks are often considered black boxes because it's hard to understand why they make certain predictions. Grad-CAM (Gradient-weighted Class Activation Mapping) helps visualize the regions of an image that influence the model’s decision.

* **Bright regions (red/yellow)** - Strong influence on prediction

* **Dark regions (blue)** - Less influence

# **Performance metrics**

It helps us understand how well the model is classifying images. They guide us in diagnosing issues like overfitting, underfitting, and class imbalance.

For image classification, the most common evaluation metrics include:
*  **Accuracy** – Measures the percentage of correctly classified images.
* **Confusion Matrix** – Shows how well the model distinguishes between different classes.
* **F1-Score** – A balance between Precision & Recall, useful when dealing with imbalanced classes.
* **Loss & Accuracy Curves** – Helps visualize model convergence during training.

\section{Code Listings}
\subsection*{Code 1}
\begin{lstlisting}[language=Python]
from google.colab import drive
drive.mount('/content/drive')
\end{lstlisting}

\subsection*{Code 2}
\begin{lstlisting}[language=Python]
!sudo update-alternatives --config python3

\end{lstlisting}

\subsection*{Code 3}
\begin{lstlisting}[language=Python]
!pip install --upgrade pip
!pip install grad-cam --no-cache-dir
!pip install torch torchvision numpy matplotlib opencv-python
\end{lstlisting}

\subsection*{Code 4}
\begin{lstlisting}[language=Python]
!apt update && apt install python3-pip -y
\end{lstlisting}

\subsection*{Code 5}
\begin{lstlisting}[language=Python]
!pip --version
\end{lstlisting}

\subsection*{Code 6}
\begin{lstlisting}[language=Python]
!pip install grad-cam

\end{lstlisting}

\subsection*{Code 7}
\begin{lstlisting}[language=Python]
!pip show grad-cam

\end{lstlisting}

\subsection*{Code 8}
\begin{lstlisting}[language=Python]
!pip --version

\end{lstlisting}

\subsection*{Code 9}
\begin{lstlisting}[language=Python]
!pip install grad-cam

\end{lstlisting}

\subsection*{Code 10}
\begin{lstlisting}[language=Python]
!pip show grad-cam

\end{lstlisting}

\subsection*{Code 11}
\begin{lstlisting}[language=Python]
from pytorch_grad_cam import GradCAM
print("✅ Grad-CAM imported successfully!")

\end{lstlisting}

\subsection*{Code 12}
\begin{lstlisting}[language=Python]
!pip install torch torchvision torchaudio
!pip install grad-cam

\end{lstlisting}

\subsection*{Code 13}
\begin{lstlisting}[language=Python]
!pip show grad-cam

\end{lstlisting}

\subsection*{Code 14}
\begin{lstlisting}[language=Python]
from pytorch_grad_cam import GradCAM
print("✅ PyTorch Grad-CAM imported successfully!")

\end{lstlisting}

\subsection*{Code 15}
\begin{lstlisting}[language=Python]
import torch
import torchvision.models as models
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import preprocess_image

# Load a pretrained model
model = models.resnet18(pretrained=True)
model.eval()

# Select the last convolutional layer
target_layer = model.layer4[1].conv2

# Initialize Grad-CAM
cam = GradCAM(model=model, target_layers=[target_layer])

print("✅ Grad-CAM is ready to use!")

\end{lstlisting}

\subsection*{Code 16}
\begin{lstlisting}[language=Python]
from google.colab import files
files.upload()
\end{lstlisting}

\subsection*{Code 17}
\begin{lstlisting}[language=Python]
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
\end{lstlisting}

\subsection*{Code 18}
\begin{lstlisting}[language=Python]
!kaggle datasets download -d alessiocorrado99/animals10
!unzip animals10.zip -d /content/animal10
\end{lstlisting}

\subsection*{Code 19}
\begin{lstlisting}[language=Python]
import os
print(os.listdir("/content/animal10"))
\end{lstlisting}

\subsection*{Code 20}
\begin{lstlisting}[language=Python]
import torch
import torchvision
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import os

\end{lstlisting}

\subsection*{Code 21}
\begin{lstlisting}[language=Python]
# Define transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize images to 224x224
    transforms.ToTensor(),  # Convert images to tensors
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values
])
\end{lstlisting}

\subsection*{Code 22}
\begin{lstlisting}[language=Python]
# Set dataset path
dataset_path = "animal10/raw-img"

# Load dataset
dataset = datasets.ImageFolder(root=dataset_path, transform=transform)

# Split dataset into training and validation
train_size = int(0.8 * len(dataset))  # 80% training
val_size = len(dataset) - train_size  # 20% validation
train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

print(f"Training samples: {len(train_dataset)} | Validation samples: {len(val_dataset)}")

\end{lstlisting}

\subsection*{Code 23}
\begin{lstlisting}[language=Python]
# Function to show images
def show_images(dataloader):
    data_iter = iter(dataloader)
    images, labels = next(data_iter)

    fig, axes = plt.subplots(1, 5, figsize=(15, 5))
    for i in range(5):
        img = images[i].permute(1, 2, 0)  # Change dimension order for visualization
        img = img * 0.5 + 0.5  # De-normalize
        axes[i].imshow(img)
        axes[i].axis("off")

    plt.show()

# Display some training images
show_images(train_loader)
\end{lstlisting}

\subsection*{Code 24}
\begin{lstlisting}[language=Python]
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
\end{lstlisting}

\subsection*{Code 25}
\begin{lstlisting}[language=Python]
# Load pre-trained ResNet18 model
model = models.resnet18(pretrained=True)

# Modify the final layer to match our number of classes
num_classes = len(train_dataset.dataset.classes)  # Number of animal categories
model.fc = nn.Linear(model.fc.in_features, num_classes)

# Move model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

print("Model loaded successfully on:", device)

\end{lstlisting}

\subsection*{Code 26}
\begin{lstlisting}[language=Python]
# Loss function
criterion = nn.CrossEntropyLoss()

# Optimizer (Adam is usually a good choice)
optimizer = optim.Adam(model.parameters(), lr=0.001)
\end{lstlisting}

\subsection*{Code 27}
\begin{lstlisting}[language=Python]
# Training function
def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5):
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # Track loss and accuracy
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)

        train_loss = running_loss / len(train_loader)
        train_acc = correct / total * 100

        print(f"Epoch {epoch+1}: Loss = {train_loss:.4f}, Accuracy = {train_acc:.2f}%")

# Train the model for 5 epochs
train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5)

\end{lstlisting}

\subsection*{Code 28}
\begin{lstlisting}[language=Python]
# Save trained model
torch.save(model.state_dict(), "animal10_resnet18.pth")
print("Model saved successfully!")
\end{lstlisting}

\subsection*{Code 29}
\begin{lstlisting}[language=Python]
from torchvision import transforms

# Augment training images
transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),  # Flip images randomly
    transforms.RandomRotation(10),  # Rotate images randomly
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Random crop
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color variation
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Validation set (No augmentation)
transform_val = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])
\end{lstlisting}

\subsection*{Code 30}
\begin{lstlisting}[language=Python]
# Reload dataset with augmentation
train_dataset = datasets.ImageFolder(root=dataset_path, transform=transform_train)
val_dataset = datasets.ImageFolder(root=dataset_path, transform=transform_val)

# Split dataset
train_size = int(0.8 * len(train_dataset))
val_size = len(train_dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

print(f"Dataset reloaded with augmentation: {len(train_dataset)} training images | {len(val_dataset)} validation images")

\end{lstlisting}

\subsection*{Code 31}
\begin{lstlisting}[language=Python]
train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5)

\end{lstlisting}

\subsection*{Code 32}
\begin{lstlisting}[language=Python]
import torch
import torchvision.transforms as transforms
from PIL import Image
import cv2
import numpy as np
import matplotlib.pyplot as plt
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import preprocess_image

\end{lstlisting}

\subsection*{Code 33}
\begin{lstlisting}[language=Python]
import torchvision.models as models

# Load a pretrained ResNet50 model
model = models.resnet50(pretrained=True)
model.eval()  # Set to evaluation mode

# Select the last convolutional layer
target_layer = model.layer4[-1]

\end{lstlisting}

\subsection*{Code 34}
\begin{lstlisting}[language=Python]
import os

dataset_path = "animal10/raw-img"  # Adjust the path if needed
for category in os.listdir(dataset_path):
    class_path = os.path.join(dataset_path, category)
    if os.path.isdir(class_path):
        print(f"✅ Found category: {category}, Images: {len(os.listdir(class_path))}")

\end{lstlisting}

\subsection*{Code 35}
\begin{lstlisting}[language=Python]
import cv2

image_path = "animal10/raw-img/gatto/1.jpeg"  # Change to an actual image
img = cv2.imread(image_path)
if img is None:
    print("⚠️ Image not loaded. Check file path or format.")
else:
    print("✅ Image loaded successfully!")

\end{lstlisting}

\subsection*{Code 36}
\begin{lstlisting}[language=Python]
from google.colab.patches import cv2_imshow
cv2_imshow(img)

\end{lstlisting}

\subsection*{Code 37}
\begin{lstlisting}[language=Python]
!pip install grad-cam --quiet

import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision import datasets
import cv2
import numpy as np
import matplotlib.pyplot as plt
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import preprocess_image
from google.colab.patches import cv2_imshow  # For displaying images in Colab

\end{lstlisting}

\subsection*{Code 38}
\begin{lstlisting}[language=Python]
# Load a pre-trained model (or use your trained model)
model = models.resnet18(pretrained=True)
model.eval()

# If using your trained model, load it like this:
# model.load_state_dict(torch.load("your_model.pth", map_location=torch.device('cpu')))
# model.eval()

\end{lstlisting}

\subsection*{Code 39}
\begin{lstlisting}[language=Python]
# For ResNet, the last convolutional layer is 'layer4'
target_layers = [model.layer4]

\end{lstlisting}

\subsection*{Code 40}
\begin{lstlisting}[language=Python]
# Load and preprocess image
test_image_path = "animal10/raw-img/gatto/6.jpeg"  # Change path to an actual image
img = cv2.imread(test_image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_resized = cv2.resize(img, (224, 224))  # Resize to model input size

# Convert to tensor for Grad-CAM
input_tensor = preprocess_image(img_resized, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
\end{lstlisting}

\subsection*{Code 41}
\begin{lstlisting}[language=Python]
# Initialize Grad-CAM
cam = GradCAM(model=model, target_layers=target_layers)

# Generate heatmap
grayscale_cam = cam(input_tensor=input_tensor, targets=None)
grayscale_cam = grayscale_cam[0, :]  # Get the first (only) image's CAM

# Overlay heatmap on the original image
heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)
superimposed_img = cv2.addWeighted(img_resized, 0.5, heatmap, 0.5, 0)

# Display result
cv2_imshow(superimposed_img)

\end{lstlisting}

\subsection*{Code 42}
\begin{lstlisting}[language=Python]
# Load and preprocess image
test_image_path = "animal10/raw-img/mucca/OIP-3JcOkhfMrqxzvcl8MOkhMAHaEK.jpeg"  # Change path to an actual image
img = cv2.imread(test_image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_resized = cv2.resize(img, (224, 224))  # Resize to model input size

# Convert to tensor for Grad-CAM
input_tensor = preprocess_image(img_resized, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
\end{lstlisting}

\subsection*{Code 43}
\begin{lstlisting}[language=Python]
# Initialize Grad-CAM
cam = GradCAM(model=model, target_layers=target_layers)

# Generate heatmap
grayscale_cam = cam(input_tensor=input_tensor, targets=None)
grayscale_cam = grayscale_cam[0, :]  # Get the first (only) image's CAM

# Overlay heatmap on the original image
heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)
superimposed_img = cv2.addWeighted(img_resized, 0.5, heatmap, 0.5, 0)

# Display result
cv2_imshow(superimposed_img)
\end{lstlisting}

\subsection*{Code 44}
\begin{lstlisting}[language=Python]
# Load and preprocess image
test_image_path = "animal10/raw-img/ragno/e83cb3062bf1003ed1584d05fb1d4e9fe777ead218ac104497f5c97ca5edb3bd_640.jpg"  # Change path to an actual image
img = cv2.imread(test_image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_resized = cv2.resize(img, (224, 224))  # Resize to model input size

# Convert to tensor for Grad-CAM
input_tensor = preprocess_image(img_resized, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
\end{lstlisting}

\subsection*{Code 45}
\begin{lstlisting}[language=Python]
# Initialize Grad-CAM
cam = GradCAM(model=model, target_layers=target_layers)

# Generate heatmap
grayscale_cam = cam(input_tensor=input_tensor, targets=None)
grayscale_cam = grayscale_cam[0, :]  # Get the first (only) image's CAM

# Overlay heatmap on the original image
heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)
superimposed_img = cv2.addWeighted(img_resized, 0.5, heatmap, 0.5, 0)

# Display result
cv2_imshow(superimposed_img)
\end{lstlisting}

\subsection*{Code 46}
\begin{lstlisting}[language=Python]
# Load and preprocess image
test_image_path = "animal10/raw-img/scoiattolo/OIP-_flk9r3BRf3VxU5zWSep5QHaE8.jpeg"  # Change path to an actual image
img = cv2.imread(test_image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_resized = cv2.resize(img, (224, 224))  # Resize to model input size

# Convert to tensor for Grad-CAM
input_tensor = preprocess_image(img_resized, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
\end{lstlisting}

\subsection*{Code 47}
\begin{lstlisting}[language=Python]
# Initialize Grad-CAM
cam = GradCAM(model=model, target_layers=target_layers)

# Generate heatmap
grayscale_cam = cam(input_tensor=input_tensor, targets=None)
grayscale_cam = grayscale_cam[0, :]  # Get the first (only) image's CAM

# Overlay heatmap on the original image
heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)
superimposed_img = cv2.addWeighted(img_resized, 0.5, heatmap, 0.5, 0)

# Display result
cv2_imshow(superimposed_img)
\end{lstlisting}

\subsection*{Code 48}
\begin{lstlisting}[language=Python]
# Load and preprocess image
test_image_path = "animal10/raw-img/pecora/e83db50a28f1073ed1584d05fb1d4e9fe777ead218ac104497f5c978a6ebb3bf_640.jpg"  # Change path to an actual image
img = cv2.imread(test_image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_resized = cv2.resize(img, (224, 224))  # Resize to model input size

# Convert to tensor for Grad-CAM
input_tensor = preprocess_image(img_resized, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
\end{lstlisting}

\subsection*{Code 49}
\begin{lstlisting}[language=Python]
# Initialize Grad-CAM
cam = GradCAM(model=model, target_layers=target_layers)

# Generate heatmap
grayscale_cam = cam(input_tensor=input_tensor, targets=None)
grayscale_cam = grayscale_cam[0, :]  # Get the first (only) image's CAM

# Overlay heatmap on the original image
heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)
superimposed_img = cv2.addWeighted(img_resized, 0.5, heatmap, 0.5, 0)

# Display result
cv2_imshow(superimposed_img)
\end{lstlisting}

\subsection*{Code 50}
\begin{lstlisting}[language=Python]
# Load and preprocess image
test_image_path = "animal10/raw-img/cane/OIP-_fwokLb_Tpmj7UOicaeK0gHaHa.jpeg"  # Change path to an actual image
img = cv2.imread(test_image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_resized = cv2.resize(img, (224, 224))  # Resize to model input size

# Convert to tensor for Grad-CAM
input_tensor = preprocess_image(img_resized, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
\end{lstlisting}

\subsection*{Code 51}
\begin{lstlisting}[language=Python]
# Initialize Grad-CAM
cam = GradCAM(model=model, target_layers=target_layers)

# Generate heatmap
grayscale_cam = cam(input_tensor=input_tensor, targets=None)
grayscale_cam = grayscale_cam[0, :]  # Get the first (only) image's CAM

# Overlay heatmap on the original image
heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)
superimposed_img = cv2.addWeighted(img_resized, 0.5, heatmap, 0.5, 0)

# Display result
cv2_imshow(superimposed_img)
\end{lstlisting}

\subsection*{Code 52}
\begin{lstlisting}[language=Python]
# Load and preprocess image
test_image_path = "animal10/raw-img/cavallo/OIP-0iJXerlE-7TrM413RCZm5AHaEK.jpeg"  # Change path to an actual image
img = cv2.imread(test_image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_resized = cv2.resize(img, (224, 224))  # Resize to model input size

# Convert to tensor for Grad-CAM
input_tensor = preprocess_image(img_resized, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
\end{lstlisting}

\subsection*{Code 53}
\begin{lstlisting}[language=Python]
# Initialize Grad-CAM
cam = GradCAM(model=model, target_layers=target_layers)

# Generate heatmap
grayscale_cam = cam(input_tensor=input_tensor, targets=None)
grayscale_cam = grayscale_cam[0, :]  # Get the first (only) image's CAM

# Overlay heatmap on the original image
heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)
superimposed_img = cv2.addWeighted(img_resized, 0.5, heatmap, 0.5, 0)

# Display result
cv2_imshow(superimposed_img)
\end{lstlisting}

\subsection*{Code 54}
\begin{lstlisting}[language=Python]
# Load and preprocess image
test_image_path = "animal10/raw-img/elefante/e83db30d2df5073ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640.jpg"  # Change path to an actual image
img = cv2.imread(test_image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_resized = cv2.resize(img, (224, 224))  # Resize to model input size

# Convert to tensor for Grad-CAM
input_tensor = preprocess_image(img_resized, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
\end{lstlisting}

\subsection*{Code 55}
\begin{lstlisting}[language=Python]
# Initialize Grad-CAM
cam = GradCAM(model=model, target_layers=target_layers)

# Generate heatmap
grayscale_cam = cam(input_tensor=input_tensor, targets=None)
grayscale_cam = grayscale_cam[0, :]  # Get the first (only) image's CAM

# Overlay heatmap on the original image
heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)
superimposed_img = cv2.addWeighted(img_resized, 0.5, heatmap, 0.5, 0)

# Display result
cv2_imshow(superimposed_img)
\end{lstlisting}

\subsection*{Code 56}
\begin{lstlisting}[language=Python]
# Load and preprocess image
test_image_path = "animal10/raw-img/farfalla/e83db70d28f31c22d2524518b7444f92e37fe5d404b0144390f8c770a2e9b5_640.jpg"  # Change path to an actual image
img = cv2.imread(test_image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_resized = cv2.resize(img, (224, 224))  # Resize to model input size

# Convert to tensor for Grad-CAM
input_tensor = preprocess_image(img_resized, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
\end{lstlisting}

\subsection*{Code 57}
\begin{lstlisting}[language=Python]
# Initialize Grad-CAM
cam = GradCAM(model=model, target_layers=target_layers)

# Generate heatmap
grayscale_cam = cam(input_tensor=input_tensor, targets=None)
grayscale_cam = grayscale_cam[0, :]  # Get the first (only) image's CAM

# Overlay heatmap on the original image
heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)
superimposed_img = cv2.addWeighted(img_resized, 0.5, heatmap, 0.5, 0)

# Display result
cv2_imshow(superimposed_img)
\end{lstlisting}

\subsection*{Code 58}
\begin{lstlisting}[language=Python]
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Function to evaluate model performance
def evaluate_model(model, dataloader, device):
    model.eval()  # Set model to evaluation mode
    y_true = []
    y_pred = []

    with torch.no_grad():  # Disable gradient computation
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)  # Get predicted class

            y_true.extend(labels.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())

    return y_true, y_pred

\end{lstlisting}

\subsection*{Code 59}
\begin{lstlisting}[language=Python]
import torchvision.transforms as transforms

transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize all images
    transforms.ToTensor(),          # Convert to tensor
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize
])

\end{lstlisting}

\subsection*{Code 60}
\begin{lstlisting}[language=Python]
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),  # Flip images randomly
    transforms.RandomRotation(15),      # Rotate randomly
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Shift image slightly
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

\end{lstlisting}

\subsection*{Code 61}
\begin{lstlisting}[language=Python]
from torch.utils.data import DataLoader
import torch.nn as nn
import torch

# Calculate class weights
class_counts = [500, 800, 1200, 200, 900, 300, 400, 1000, 600, 700]  # Replace with actual class counts
class_weights = torch.tensor([1.0 / count for count in class_counts])
class_weights = class_weights.to("cuda")  # Move to GPU if needed

# Apply weighted CrossEntropyLoss
criterion = nn.CrossEntropyLoss(weight=class_weights)

\end{lstlisting}

\subsection*{Code 62}
\begin{lstlisting}[language=Python]
import torchvision.models as models

model = models.resnet50(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 10)  # 10 classes in Animal-10
model = model.to("cuda")

\end{lstlisting}

\subsection*{Code 63}
\begin{lstlisting}[language=Python]
import torch.optim as optim

optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # Reduce LR every 5 epochs

\end{lstlisting}

\subsection*{Code 64}
\begin{lstlisting}[language=Python]
import torch.nn as nn

class ImprovedCNN(nn.Module):
    def __init__(self):
        super(ImprovedCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(64)  # Normalize activations
        self.dropout = nn.Dropout(0.4)  # Dropout to prevent overfitting
        self.fc = nn.Linear(64 * 56 * 56, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = nn.ReLU()(x)
        x = self.dropout(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

\end{lstlisting}

\subsection*{Code 65}
\begin{lstlisting}[language=Python]
from sklearn.metrics import accuracy_score, f1_score

def evaluate_model(model, test_loader, device):
    model.eval()
    y_true, y_pred = [], []

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())

    acc = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average="weighted")

    print(f"Accuracy: {acc:.4f}, F1-Score: {f1:.4f}")
    return acc, f1

\end{lstlisting}

\subsection*{Code 66}
\begin{lstlisting}[language=Python]
import matplotlib.pyplot as plt

def plot_training(history):
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(history["train_loss"], label="Train Loss")
    plt.plot(history["val_loss"], label="Validation Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend()
    plt.title("Loss Curve")

    plt.subplot(1, 2, 2)
    plt.plot(history["train_acc"], label="Train Accuracy")
    plt.plot(history["val_acc"], label="Validation Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.title("Accuracy Curve")

    plt.show()

\end{lstlisting}

\subsection*{Code 67}
\begin{lstlisting}[language=Python]
import torch
from sklearn.metrics import accuracy_score, f1_score

def evaluate_model(model, test_loader, device):
    model.eval()
    y_true, y_pred = [], []

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())

    acc = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average="weighted")

    print(f"✅ Accuracy: {acc:.4f}, F1-Score: {f1:.4f}")
    return y_true, y_pred, acc, f1

\end{lstlisting}

\subsection*{Code 68}
\begin{lstlisting}[language=Python]
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

def plot_confusion_matrix(y_true, y_pred, class_names):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix")
    plt.show()

\end{lstlisting}

\subsection*{Code 69}
\begin{lstlisting}[language=Python]
history = {"train_loss": [], "val_loss": [], "train_acc": [], "val_acc": []}

def train_model(model, train_loader, val_loader, criterion, optimizer, epochs, device):
    for epoch in range(epochs):
        model.train()
        train_loss, train_correct = 0.0, 0
        total_samples = 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * images.size(0)
            _, preds = torch.max(outputs, 1)
            train_correct += (preds == labels).sum().item()
            total_samples += labels.size(0)

        train_loss /= total_samples
        train_acc = train_correct / total_samples

        # Validation Phase
        model.eval()
        val_loss, val_correct = 0.0, 0
        total_samples = 0

        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)

                val_loss += loss.item() * images.size(0)
                _, preds = torch.max(outputs, 1)
                val_correct += (preds == labels).sum().item()
                total_samples += labels.size(0)

        val_loss /= total_samples
        val_acc = val_correct / total_samples

        # Store history
        history["train_loss"].append(train_loss)
        history["val_loss"].append(val_loss)
        history["train_acc"].append(train_acc)
        history["val_acc"].append(val_acc)

        print(f"Epoch [{epoch+1}/{epochs}] | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}")

    return history

\end{lstlisting}

\subsection*{Code 70}
\begin{lstlisting}[language=Python]
def plot_training_curves(history):
    plt.figure(figsize=(12, 5))

    # Loss Curve
    plt.subplot(1, 2, 1)
    plt.plot(history["train_loss"], label="Train Loss", marker="o")
    plt.plot(history["val_loss"], label="Validation Loss", marker="o")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend()
    plt.title("Loss Curve")

    # Accuracy Curve
    plt.subplot(1, 2, 2)
    plt.plot(history["train_acc"], label="Train Accuracy", marker="o")
    plt.plot(history["val_acc"], label="Validation Accuracy", marker="o")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.title("Accuracy Curve")

    plt.show()

\end{lstlisting}

\subsection*{Code 71}
\begin{lstlisting}[language=Python]
from torchvision import datasets

# Define your dataset path
dataset_path = "animal10/raw-img"  # Change this if your dataset is in a different location

# Load dataset
dataset = datasets.ImageFolder(root=dataset_path)

# Print class names
class_names = dataset.classes
print("Class Names:", class_names)

\end{lstlisting}

\subsection*{Code 72}
\begin{lstlisting}[language=Python]
# Train the model
history = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10, device="cuda")

# Plot training curves
plot_training_curves(history)

# Evaluate the model
y_true, y_pred, acc, f1 = evaluate_model(model, test_loader, "cuda")

# Confusion Matrix
class_names = ["cane", "cavallo", "elefante", "farfalla", "gallina", "gatto", "mucca", "pecora", "ragno", "scoiattolo"]  # Update based on Animal-10 classes
plot_confusion_matrix(y_true, y_pred, class_names)

\end{lstlisting}

\subsection*{Code 73}
\begin{lstlisting}[language=Python]

\end{lstlisting}

\end{document}
